<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>统计学习方法——感知机</title>
    <link href="/2025/04/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    <url>/2025/04/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="统计学习方法感知机">统计学习方法——感知机</h1><img src="/2025/04/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E6%84%9F%E7%9F%A5%E6%9C%BA/image1.png" class=""><h2 id="什么是感知机">什么是感知机</h2><p>感知机是一个二分类线性判别模型，假设输入<spanclass="math inline"><em>x</em> ∈ ℝ<sup><em>n</em></sup></span>，输出<spanclass="math inline"><em>y</em> ∈ −1, +1</span>，感知机为如下函数： <spanclass="math display">$$f(x)=sign(w^Tx+b),\\sign(z)=\begin{cases}1 &amp; z \ge 0 \\-1 &amp;  z &lt; 0 \\\end{cases}$$</span>其中，w叫做权重，是分类超平面的法向量；b叫做偏置，是超平面的截距。</p><p><span class="math inline"><em>x</em></span>和<spanclass="math inline"><em>w</em></span>都是向量，比如在上面的图2.1中，<spanclass="math inline"><em>x</em></span>就是2维的，因为数据平面的横轴和竖轴分别是<spanclass="math inline"><em>x</em><sup>(1)</sup></span>和<spanclass="math inline"><em>x</em><sup>(2)</sup></span>，感知机本质上是给每个特征加个权重<spanclass="math inline"><em>w</em></span>和偏置<spanclass="math inline"><em>b</em></span>从而进行分类的，因此如果数据落在超平面上，则<spanclass="math inline"><em>w</em><sup><em>T</em></sup><em>x</em> + <em>b</em></span>就为0，落上超平面的上方则大于0，下方小于0。</p><p>设数据集线性可分，感知机的损失函数为所有误分类点到分类超平面的函数间隔，即：<spanclass="math display"><em>L</em>(<em>w</em>, <em>b</em>) = −∑<sub><em>x</em><sub><em>i</em></sub> ∈ <em>M</em></sub><em>y</em><sub><em>i</em></sub>(<em>w</em> ⋅ <em>x</em><sub><em>i</em></sub> + <em>b</em>)</span>几何间隔和函数间隔的区别我没有提到，在文中下面给出的b站视频中，有详细的解释</p><ul><li><p>为什么感知机不使用几何间隔</p><p>由于感知机的前提是原数据集线性可分，这意味着必须存在一个正确的超平面。那么，不管几何距离还是函数距离，损失函数最后都要等于0，因此感知机并不关心点到超平面之间的间隔，关心的是误分类的点的个数。采用几何间隔其实也可以，但是会使学习过程复杂化。</p></li></ul><h2 id="感知机的原始形式">感知机的原始形式</h2><p>给定一个训练的数据集<spanclass="math inline"><em>T</em> = (<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>), (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>), .., (<em>x</em><sub><em>N</em></sub>, <em>y</em><sub><em>N</em></sub>)</span>，其中<spanclass="math inline"><em>x</em><sub><em>i</em></sub> ∈ ℝ<sup><em>n</em></sup></span>，<spanclass="math inline"><em>Y</em><sub><em>i</em></sub> ∈ −1, 1</span>，$ i=1,2,3….N<spanclass="math inline">。<em>感</em><em>知</em><em>机</em></span>sign(wx+b)<spanclass="math inline"><em>的</em><em>损</em><em>失</em><em>函</em><em>数</em><em>为</em>:</span>$<em>{w,b}L(w,b)=-</em>{x_iM}y_i(wx_i+b) <span class="math display">$$其中M为误分类点的集合，有了损失函数分别对w和b求偏导就可以得到梯度了，损失函数$L(w,b)$的梯度为：$$</span> <em>w L(w,b) = -</em>{x_iM}y_ix_i \ <em>b L(w,b) = -</em>{x_iM}y_i <span class="math display">$$接着就可以随机选取一个失误分类$(x_i,y_i)$，对w,b进行更新:$$</span> w w+y_ix_i \ b b+y_i $$</p><p><strong>其中<spanclass="math inline"><em>η</em>(0 &lt; <em>η</em> ≤ 1)</span>是步长，又称为学习率，在本文中如果不做详细说明一般取1</strong></p><p>可以得到如下的算法了:</p><p>输入：训练数据<spanclass="math inline"><em>T</em> = (<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>), (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>), .., (<em>x</em><sub><em>N</em></sub>, <em>y</em><sub><em>N</em></sub>)</span>，其中<spanclass="math inline"><em>x</em><sub><em>i</em></sub> ∈ ℝ<sup><em>n</em></sup></span>，<spanclass="math inline"><em>Y</em><sub><em>i</em></sub> ∈ −1, 1</span>；学习率<spanclass="math inline"><em>η</em> ∈ (0, 1]</span></p><p>输出：w,b；感知机模型<spanclass="math inline"><em>f</em>(<em>x</em>) = <em>s</em><em>i</em><em>g</em><em>n</em>(<em>w</em><sup><em>T</em></sup><em>x</em> + <em>b</em>)</span></p><ul><li><p>随机任选一个超平面<spanclass="math inline"><em>w</em><sub>0</sub>, <em>b</em><sub>0</sub></span>，一般都初始化为0</p></li><li><p>在训练集中选取数据<spanclass="math inline">(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span></p></li><li><p>如果<spanclass="math inline"><em>y</em><sub><em>i</em></sub>(<em>w</em><sup><em>T</em></sup><em>x</em><sub><em>i</em></sub> + <em>b</em>) ≤ 0</span>，则更新w和b：</p><p>​ <span class="math display">$$ w=w+\eta y_ix_i \\b=b+\eta y_i$$</span></p></li><li><p>转至第二步，直到训练集中没有误分点</p></li></ul><p>这个算法的流程简单来说就是：刚开始初始化超平面为0，然后选取第一个数据，如果结果小于等于0的话，那么就更新w和b，然后用更新后的新模型再次遍历所有数据，碰到错误情况就重复：更新w和b，遍历所有数据这个操作。直到找到合适的w和b满足所有的数据。</p><p><strong>具体的例子可看统计学习方法第29页</strong></p><h2 id="感知机的对偶性质">感知机的对偶性质</h2><p><del>假设样本点<spanclass="math inline">(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span>在更新的过程中被使用了<spanclass="math inline"><em>n</em><sub><em>i</em></sub></span>次，因此，从原始形式的学习过程可以得到，最后学习到的<spanclass="math inline"><em>w</em></span>和<spanclass="math inline"><em>b</em></span>可以分别表示为：</del> <spanclass="math display">$$w=\sum_{i=1}^Nn_i \eta y_ix_i \\b=\sum_{i=1}^Nn_i \eta y_i$$</span> <del><strong><spanclass="math inline"><em>n</em><sub><em>i</em></sub></span>的含义：</strong></del></p><p>​ <del>如果<spanclass="math inline"><em>n</em><sub><em>i</em></sub></span>的值越大，那么意味着这个样本点经常为误分。说明这个点就是离超平面很近的点。超平面稍微移动一点点，这个点就会被归结到别的类别中。</del></p><p><del>那么此时感知机的公式就可以写为：</del> <spanclass="math display">$$f(x)=sign(w \cdot x +b)=sign(\sum_{j=1}^Nn_j \eta y_jx_j \cdotx_i+\sum_{i=j}^Nn_j \eta y_j)$$</span> <del><strong>此时，学习的目标就不再是<spanclass="math inline"><em>w</em></span>和<spanclass="math inline"><em>b</em></span>，而是<spanclass="math inline"><em>n</em><sub><em>i</em></sub>, <em>i</em> = 1, 2, 3...., <em>N</em></span></strong></del></p><p><del>当然为了和书本同一，我们可以定义<spanclass="math inline"><em>α</em><sub><em>i</em></sub> = <em>n</em><sub><em>i</em></sub><em>η</em></span>，也可以上式中的第二项换为b，都不影响。</del></p><p><del>替换过后，w和b的式子为：</del> <span class="math display">$$w=\sum_{i=1}^N\alpha_iy_ix_i \\b=\sum_{i=1}^N\alpha_iy_i$$</span> <del>具体算法为：</del></p><p><del>输入：训练数据集<spanclass="math inline"><em>T</em> = (<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>), (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>), .., (<em>x</em><sub><em>N</em></sub>, <em>y</em><sub><em>N</em></sub>)</span>，其中<spanclass="math inline"><em>x</em><sub><em>i</em></sub> ∈ ℝ<sup><em>n</em></sup></span>，<spanclass="math inline"><em>Y</em><sub><em>i</em></sub> ∈ −1, 1</span>；学习率<spanclass="math inline"><em>η</em> ∈ (0, 1]</span></del></p><p><del>输出：<spanclass="math inline"><em>α</em></span>,b；感知机模型更新为：</del><br /><span class="math display">$$f(x)=sign(\sum_{i=1}^N\alpha_iy_ix_i\cdot x+b)$$</span> <del>其中<spanclass="math inline"><em>α</em> = (<em>α</em><sub>1</sub>, <em>α</em><sub>2</sub>, ..., <em>α</em><sub><em>N</em></sub>)<sup><em>T</em></sup></span></del></p><ul><li><p><del>令<spanclass="math inline"><em>α</em> = <strong>0</strong>, <em>b</em> = 0</span></del></p></li><li><p><del>在训练集中选取数据<spanclass="math inline">(<em>x</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span></del></p></li><li><p><del>如果<spanclass="math inline">$y_i(\sum_{j=1}^N\alpha_jy_jx_j\cdot x_i+b)\le0$</span>，则更新<span class="math inline"><em>α</em></span>和b:</del><span class="math display">$$\alpha_i=\alpha_i+\eta \\b=b+\eta y_i$$</span></p></li><li><p><del>转至第二步，直到训练集中没有误分点</del></p></li></ul><p><del><strong>再次强调，<spanclass="math inline"><em>α</em><sub><em>i</em></sub></span>是第i个数据在更新过程中被使用到的次数（也就是第i个数据误分的次数）和<spanclass="math inline"><em>η</em></span>的乘积，而本文一直将<spanclass="math inline"><em>η</em></span>设置为1</strong></del></p><p><del>这个算法流程简单来说就是: 先初始化<spanclass="math inline"><em>α</em> = <strong>0</strong>, <em>b</em> = 0</span>,然后将第1个数据带入，如果误分，然后更新参数<spanclass="math inline"><em>α</em><sub>1</sub> = <em>α</em><sub>1</sub> + <em>η</em></span>，$b=b+y_1$ ，接着再次遍历数据，如果碰到误分就执行<spanclass="math inline"><em>α</em><sub><em>i</em></sub> = <em>α</em><sub><em>i</em></sub> + <em>η</em></span>，<spanclass="math inline"><em>b</em> = <em>b</em> + <em>η</em><em>y</em><sub><em>i</em></sub></span>操作，直到没有误分。</del></p><p><strong>具体的例子可看统计学习方法第34页</strong></p><p>对偶性这里参考了知乎上的回答（==<u><strong><em>前面写的都是狗屎，直接看这个回答</em></strong></u>==）</p><img src="/2025/04/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E6%84%9F%E7%9F%A5%E6%9C%BA/image2.jpg" class=""><p>这个回答和李航书中讲的角度不一样，但是解释的非常好！而且训练过程也有不同的地方，因为没有用<spanclass="math inline"><em>α</em><sub><em>i</em></sub></span>，因为这个回答的所有操作都是对<spanclass="math inline"><em>n</em><sub><em>i</em></sub></span>进行的，在更新时，是将<spanclass="math inline"><em>n</em><sub><em>i</em></sub> + 1</span>，这个公式和书中的<spanclass="math inline"><em>α</em><sub><em>i</em></sub> = <em>α</em><sub><em>i</em></sub> + <em>η</em></span>本质是一样的。</p><p>因为<spanclass="math inline"><em>α</em><sub><em>i</em></sub> = <em>n</em><sub><em>i</em></sub><em>η</em></span>，所以<spanclass="math inline"><em>α</em><sub><em>i</em></sub> = （<em>n</em><sub><em>i</em></sub> + 1）<em>η</em> = <em>n</em><sub><em>i</em></sub><em>η</em> + <em>η</em> = <em>α</em><sub><em>i</em></sub> + <em>η</em></span></p><h2 id="注意">注意</h2><p>本文写的比较笼统，具体的可以看</p><p>统计学习方法第二章</p><p><ahref="https://www.bilibili.com/video/BV1i4411G7Xv?p=2">b站视频</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>统计学习方法</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo无法插入图片解决办法</title>
    <link href="/2025/04/13/Hexo%E6%97%A0%E6%B3%95%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
    <url>/2025/04/13/Hexo%E6%97%A0%E6%B3%95%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>关于Hexo图片加载不出的问题，网上有很多方案。</p><p>本质原因就是makdown的图片引用格式不适用于html。</p><p>网络上的教程有很多例如：</p><p><ahref="https://blog.csdn.net/lengcs/article/details/143816877">[2024]hexo图片无法加载究极解决方案_hexo图片显示不出来-CSDN博客</a></p><p><a href="https://www.cnblogs.com/edisonfish/p/18180672">hexo博客插入本地图片时遇到的坑 - 咸鱼Linux运维 - 博客园</a></p><p><ahref="https://blog.csdn.net/s_alted/article/details/138582550">hexo博客插入本地图片时遇到的坑_hexo-asset-img-CSDN博客</a></p><p><ahref="https://bingbytebard.com/2024/11/08/Hexo中插入图片的方法/">Hexo中插入图片的方法- Hazel</a></p><p>这些方法主要分类两类：</p><ol type="1"><li>在source目录下新建一个文件用于存储图片，但是这种方法无法用markdown预览效果了，因此我排除了。</li><li>安装插件<code>hexo-asset-img</code>（<code>hexo-asset-image</code>被hexo弃用了<strong>不要安装！！！</strong>）</li></ol><p>我安装<code>hexo-asset-img</code>后依旧没有解决问题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">npm install hexo-asset-img --save<br></code></pre></td></tr></table></figure><p>折腾半天无果只能卸载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Bash">npm uninstall hexo-asset-img<br>hexo clean<br></code></pre></td></tr></table></figure><p>后面偶然在官网上发现了另外一个轮子<code>hexo-image-link</code>，安装以后成功解决问题。</p><p><ahref="https://github.com/cocowool/hexo-image-link">cocowool/hexo-image-link:当MD中引用本地文件时，处理生成的html中的图片链接。</a></p><p><ahref="http://edulinks.cn/2020/03/14/20200314-write-hexo-with-typora/">Hexo博客写作与图片处理的经验-大江小浪</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">npm install hexo-image-link --save<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Github+Hexo构建个人网站</title>
    <link href="/2025/04/13/Github-Hexo%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
    <url>/2025/04/13/Github-Hexo%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
    
    <content type="html"><![CDATA[<p><strong>具体参考</strong>： <ahref="https://zhuanlan.zhihu.com/p/392994381">【保姆级】利用Github搭建自己的个人博客，看完就会- 知乎</a></p><p><ahref="https://blog.csdn.net/yaorongke/article/details/119089190">GitHubPages + Hexo搭建个人博客网站，史上最全教程_hexo博客-CSDN博客</a></p><p><ahref="https://blog.csdn.net/2303_76953932/article/details/145233223">超详细Hexo+GithubPages搭建个人博客教程_github pages搭建博客-CSDN博客</a></p><h3 id="环境需求">环境需求</h3><p>配置好<code>github</code>和<code>git</code></p><p>安装<code>node.js</code></p><p><ahref="https://link.zhihu.com/?target=https%3A//nodejs.org/en/download/">https://link.zhihu.com/?target=https%3A//nodejs.org/en/download/</a></p><p>安装<ahref="https://zhida.zhihu.com/search?content_id=175462290&amp;content_type=Article&amp;match_order=1&amp;q=Hexo&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ2MTM3NTgsInEiOiJIZXhvIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MTc1NDYyMjkwLCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.M_gB7rXp4AL2UhQ3uoH9rVrtnLKHu4ErSuP2dLXxW88&amp;zhida_source=entity"><code>Hexo</code></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Python">npm install -g hexo-cli<br><br></code></pre></td></tr></table></figure><p>查看版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">hexo -v<br></code></pre></td></tr></table></figure><h3 id="网页构建">网页构建</h3><p>创建一个项目<code>hexo-blog</code>并初始化</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">hexo init hexo-blogcdhexo-blog<br></code></pre></td></tr></table></figure><p>本地启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Bash">hexo g<br>hexo server<br></code></pre></td></tr></table></figure><img src="/2025/04/13/Github-Hexo%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/start.png" class=""><p>使用主题<strong>Fluid主题</strong></p><p><ahref="https://github.com/fluid-dev/hexo-theme-fluid">fluid-dev/hexo-theme-fluid::ocean: 一款 Material Design 风格的 Hexo 主题 / An elegantMaterial-Design theme for Hexo</a></p><p>具体操作可以查看github的README</p><p>下载<ahref="https://github.com/fluid-dev/hexo-theme-fluid/releases">最新release 版本</a>解压到 themes目录，并将解压出的文件夹重命名为<code>fluid</code>。</p><p>如下修改 Hexo 博客目录中的<code>_config.yml</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">theme:</span> <span class="hljs-string">fluid</span>  <span class="hljs-comment"># 指定主题</span><br><br><span class="hljs-attr">language:</span> <span class="hljs-string">zh-CN</span>  <span class="hljs-comment"># 指定语言，会影响主题显示的语言，按需修改</span><br></code></pre></td></tr></table></figure><p>首次使用主题的「关于页」需要手动创建：</p><p><code>hexo new page about</code></p><p>创建成功后，编辑博客目录下<code>/source/about/index.md</code>，添加<code>layout</code>属性。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">sakaiay</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-04-12 17:52:03</span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">about</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><p><code>layout: about</code>必须存在，并且不能修改成其他值，否则不会显示头像等样式。</p><p><strong>本地启动</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Bash">hexo g -d<br>hexo s<br></code></pre></td></tr></table></figure><p>打开以后主题如下：</p><img src="/2025/04/13/Github-Hexo%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/aboutme.png" class="" title="aboutme"><h4 id="创建文章">创建文章</h4><p>如下修改 Hexo博客目录中的<code>_config.yml</code>，打开这个配置是为了在生成文章的时候生成一个同名的资源目录用于存放图片文件。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-string">post_asset_folder:true</span><br></code></pre></td></tr></table></figure><p>执行如下命令创建一篇新文章，名为《第一篇文章》</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">hexo new post <span class="hljs-string">&quot;第一篇文章&quot;</span><br></code></pre></td></tr></table></figure><p>执行完成后在<code>source_posts</code>目录下生成了一个md文件和一个同名的资源目录(用于存放图片)</p><img src="/2025/04/13/Github-Hexo%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/firstpost.png" class=""><p>其他设置如：<strong>网页统计</strong>等可以参考官网教程和网络上其他教程</p><p><ahref="https://hexo.fluid-dev.com/docs/guide/">https://hexo.fluid-dev.com/docs/guide/</a></p><h2 id="发布到github">发布到github</h2><p>安装hexo-deployer-git</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">npminstallhexo-deployer-git --save<br></code></pre></td></tr></table></figure><p>修改 Hexo 博客目录下的 _config.yml，配置 GitHub 相关信息</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repo:</span> <span class="hljs-string">git@github.com:Sakaiay/sakaiay.github.io.git</span>  <span class="hljs-comment">#需要配置ssh密钥</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">main</span><br></code></pre></td></tr></table></figure><p>部署到GitHub</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">hexo g -d<br></code></pre></td></tr></table></figure><p>发布以后就可以通过</p><p><ahref="https://sakaiay.github.io/">https://sakaiay.github.io/</a></p><p>访问页面了</p><h2 id="常用命令">常用命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs Bash">hexo g  <span class="hljs-comment">#生成html文件</span><br>hexo d   <span class="hljs-comment">#上传到github  </span><br><span class="hljs-comment"># 上传到github并且生成html文件</span><br>hexo g -d<br>hexo s  <span class="hljs-comment">#预览网页</span><br>hexo new <span class="hljs-string">&quot;postName&quot;</span> <span class="hljs-comment">#新建文章</span><br>hexo new page <span class="hljs-string">&quot;pageName&quot;</span> <span class="hljs-comment">#新建页面</span><br>hexo clean <span class="hljs-comment">#清理缓存</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
